{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e3af03-98ee-4451-964b-bf8ab5b7e689",
   "metadata": {},
   "source": [
    "### This is a sample code snippet for training a smaller BERT model for spell checking using Neuspell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0d14c-d1f6-4596-8cdb-3057b430a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libs\n",
    "!pip install -q pytorch_pretrained_bert\n",
    "!pip install -q transformers\n",
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532bf550-a34f-4f2d-8d64-469c6273a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_KD.py\n",
    "\n",
    "\n",
    "# Lib versions\n",
    "# pytorch_version='1.10'\n",
    "# py_version='py38'\n",
    "\n",
    "\n",
    "# Headers\n",
    "from pytorch_pretrained_bert import BertAdam\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "from typing import List, Dict, Union\n",
    "from corrector_subwordbert import BertChecker\n",
    "from commons import DEFAULT_TRAINTEST_DATA_PATH\n",
    "from corrector import Corrector\n",
    "from helpers import bert_tokenize_for_valid_examples\n",
    "from helpers import load_data, load_vocab_dict, save_vocab_dict\n",
    "from helpers import load_data, load_vocab_dict, save_vocab_dict\n",
    "from helpers import train_validation_split, batch_iter, labelize, progressBar, batch_accuracy_func\n",
    "from subwordbert import create_model, load_pretrained, model_predictions, model_inference\n",
    "\n",
    "\n",
    "# Load data and split in train-validation\n",
    "data_dir = \"PATH_TO_DATA_DIR\"\n",
    "clean_file=\"CORRECT_SENTENCES\"\n",
    "corrupt_file=\"NOISY_SENTENCES\"\n",
    "validation_split=0.2\n",
    "train_data = load_data(data_dir, clean_file, corrupt_file)\n",
    "train_data, valid_data = train_validation_split(train_data, 0.8, seed=11690)\n",
    "print(\"len of train and test data: \", len(train_data), len(valid_data))\n",
    "\n",
    "\n",
    "# Load both teacher and student models\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "teacher_checker = BertChecker(\"bert-base-cased\")\n",
    "teacher_checker.from_pretrained(ckpt_path=\"PATH_TO_PRETRAINED_MODEL\", \n",
    "                                vocab_path=\"PATH_TO_VOCABS\")\n",
    "\n",
    "student_checker = BertChecker(\"google/bert_uncased_L-2_H-256_A-4\") #device=\"cuda\") nreimers/TinyBERT_L-4_H-312_v2\n",
    "student_checker.from_huggingface(bert_pretrained_name_or_path=\"google/bert_uncased_L-2_H-256_A-4\", \n",
    "                                 vocab=\"PATH_TO_VOCABS\")\n",
    "\n",
    "teacher_checker.is_model_ready()\n",
    "student_checker.is_model_ready()\n",
    "\n",
    "t_model = teacher_checker.get_model()\n",
    "s_model = student_checker.get_model()\n",
    "\n",
    "t_model.to(DEVICE)\n",
    "s_model.to(DEVICE)\n",
    "\n",
    "\n",
    "# Set training params\n",
    "TRAIN_BATCH_SIZE, VALID_BATCH_SIZE = 2, 2\n",
    "GRADIENT_ACC = 512\n",
    "n_epochs=4\n",
    "START_EPOCH, N_EPOCHS = 0, n_epochs\n",
    "CHECKPOINT_PATH = \"PATH_TO_HECKPOINT_DIR\"\n",
    "print(f\"CHECKPOINT_PATH: {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "# Create an optimizer\n",
    "param_optimizer = list(s_model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "t_total = int(len(train_data) / TRAIN_BATCH_SIZE / GRADIENT_ACC * N_EPOCHS)\n",
    "if t_total == 0:\n",
    "    t_total = 1\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=1e-3, warmup=0.1, t_total=t_total)\n",
    "\n",
    "\n",
    "# Set student model in eval mode and teacher model in train mode\n",
    "s_model.train()\n",
    "t_model.eval()\n",
    "\n",
    "\n",
    "# Define the KL loss\n",
    "loss_functionKL = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "\n",
    "# Set the KD params\n",
    "temperature = 4.0\n",
    "alpha=0.5\n",
    "\n",
    "\n",
    "# Running stats\n",
    "max_dev_acc, argmax_dev_acc = -1, -1\n",
    "patience = 100\n",
    "\n",
    "\n",
    "# Train and Eval\n",
    "for epoch_id in range(START_EPOCH, N_EPOCHS):# + 1):\n",
    "    if (epoch_id - argmax_dev_acc) > patience: # check for patience\n",
    "        print(\"patience count reached. early stopping initiated\")\n",
    "        print(\"max_dev_acc: {}, argmax_dev_acc: {}\".format(max_dev_acc, argmax_dev_acc))\n",
    "        break\n",
    " \n",
    "    # train loss and backprop\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    train_acc_count = 0.\n",
    "    print(\"train_data size: {}\".format(len(train_data)))\n",
    "\n",
    "    train_data_iter = batch_iter(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    nbatches = int(np.ceil(len(train_data) / TRAIN_BATCH_SIZE))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_id, (batch_labels, batch_sentences) in enumerate(train_data_iter):\n",
    "        st_time = time.time()\n",
    "        # set batch data for bert\n",
    "        batch_labels_, batch_sentences_, batch_bert_inp, batch_bert_splits = \\\n",
    "            bert_tokenize_for_valid_examples(batch_labels, batch_sentences)\n",
    "        if len(batch_labels_) == 0:\n",
    "            # print(\"################\")\n",
    "            print(\"Not training the following lines due to pre-processing mismatch: \\n\")\n",
    "            # print([(a, b) for a, b in zip(batch_labels, batch_sentences)])\n",
    "            # print(\"################\")\n",
    "            continue\n",
    "        else:\n",
    "            batch_labels, batch_sentences = batch_labels_, batch_sentences_\n",
    "        \n",
    "        batch_bert_inp = {k: v.to(DEVICE) for k, v in batch_bert_inp.items()}\n",
    "        batch_labels, batch_lengths = labelize(batch_labels, teacher_checker.get_vocab())\n",
    "        batch_labels = batch_labels.to(DEVICE)\n",
    "        \n",
    "        # forward\n",
    "        outputs_student_logits, s_loss = s_model(batch_bert_inp, batch_bert_splits, targets=batch_labels, logits_flag=True)\n",
    "        batch_loss = s_loss.cpu().detach().numpy()\n",
    "        train_loss += batch_loss\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs_teacher_logits, t_loss = t_model(batch_bert_inp, batch_bert_splits, targets=batch_labels, logits_flag=True)\n",
    "  \n",
    "        # Soften probabilities and compute distillation loss\n",
    "        loss_logits = (loss_functionKL(\n",
    "            F.log_softmax(outputs_student_logits / temperature, dim=-1),\n",
    "            F.softmax(outputs_teacher_logits / temperature, dim=-1)) * (temperature ** 2))\n",
    "        loss = alpha * s_loss + (1. - alpha) * loss_logits  # Return weighted student loss\n",
    "        \n",
    "        # backward\n",
    "        if GRADIENT_ACC > 1:\n",
    "            loss = loss / GRADIENT_ACC\n",
    "        loss.backward()\n",
    "        \n",
    "        # step\n",
    "        if (batch_id + 1) % GRADIENT_ACC == 0 or batch_id >= nbatches - 1:\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # compute accuracy in numpy\n",
    "        if batch_id % 10000 == 0:\n",
    "            train_acc_count += 1\n",
    "            s_model.eval()\n",
    "            with torch.no_grad():\n",
    "                _, batch_predictions = s_model(batch_bert_inp, batch_bert_splits, targets=batch_labels)\n",
    "            s_model.train()\n",
    "            batch_labels = batch_labels.cpu().detach().numpy()\n",
    "            batch_lengths = batch_lengths.cpu().detach().numpy()\n",
    "            ncorr, ntotal = batch_accuracy_func(batch_predictions, batch_labels, batch_lengths)\n",
    "            batch_acc = ncorr / ntotal\n",
    "            train_acc += batch_acc\n",
    "            \n",
    "        # update progress\n",
    "        progressBar(batch_id + 1,\n",
    "                    int(np.ceil(len(train_data) / TRAIN_BATCH_SIZE)),\n",
    "                    [\"batch_time\", \"batch_loss\", \"avg_batch_loss\", \"batch_acc\", \"avg_batch_acc\"],\n",
    "                    [time.time() - st_time, batch_loss, train_loss / (batch_id + 1), batch_acc,\n",
    "                     train_acc / train_acc_count])\n",
    "        if batch_id == 0 or (batch_id + 1) % 5000 == 0:\n",
    "            nb = int(np.ceil(len(train_data) / TRAIN_BATCH_SIZE))\n",
    "            \n",
    "    print(f\"\\nEpoch {epoch_id} train_loss: {train_loss / (batch_id + 1)}\")\n",
    "\n",
    "    # valid loss\n",
    "    valid_loss = 0.\n",
    "    valid_acc = 0.\n",
    "    print(\"valid_data size: {}\".format(len(valid_data)))\n",
    "\n",
    "    valid_data_iter = batch_iter(valid_data, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
    "    for batch_id, (batch_labels, batch_sentences) in enumerate(valid_data_iter):\n",
    "        st_time = time.time()\n",
    "        # set batch data for bert\n",
    "        batch_labels_, batch_sentences_, batch_bert_inp, batch_bert_splits = \\\n",
    "            bert_tokenize_for_valid_examples(batch_labels, batch_sentences)\n",
    "        if len(batch_labels_) == 0:\n",
    "            # print(\"################\")\n",
    "            print(\"Not validating the following lines due to pre-processing mismatch: \\n\")\n",
    "            # print([(a, b) for a, b in zip(batch_labels, batch_sentences)])\n",
    "            # print(\"################\")\n",
    "            continue\n",
    "        else:\n",
    "            batch_labels, batch_sentences = batch_labels_, batch_sentences_\n",
    "        batch_bert_inp = {k: v.to(DEVICE) for k, v in batch_bert_inp.items()}\n",
    "        batch_labels, batch_lengths = labelize(batch_labels, teacher_checker.get_vocab())\n",
    "        batch_labels = batch_labels.to(DEVICE)\n",
    "        \n",
    "        # forward\n",
    "        s_model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_loss, batch_predictions = s_model(batch_bert_inp, batch_bert_splits, targets=batch_labels)\n",
    "        s_model.train()\n",
    "        valid_loss += batch_loss\n",
    "        \n",
    "        # compute accuracy in numpy\n",
    "        batch_labels = batch_labels.cpu().detach().numpy()\n",
    "        batch_lengths = batch_lengths.cpu().detach().numpy()\n",
    "        ncorr, ntotal = batch_accuracy_func(batch_predictions, batch_labels, batch_lengths)\n",
    "        batch_acc = ncorr / ntotal\n",
    "        valid_acc += batch_acc\n",
    "        \n",
    "        # update progress\n",
    "        progressBar(batch_id + 1,\n",
    "                    int(np.ceil(len(valid_data) / VALID_BATCH_SIZE)),\n",
    "                    [\"batch_time\", \"batch_loss\", \"avg_batch_loss\", \"batch_acc\", \"avg_batch_acc\"],\n",
    "                    [time.time() - st_time, batch_loss, valid_loss / (batch_id + 1), batch_acc,\n",
    "                     valid_acc / (batch_id + 1)])\n",
    "        if batch_id == 0 or (batch_id + 1) % 2000 == 0:\n",
    "            nb = int(np.ceil(len(valid_data) / VALID_BATCH_SIZE))\n",
    "\n",
    "    print(f\"\\nEpoch {epoch_id} valid_loss: {valid_loss / (batch_id + 1)}\")\n",
    "\n",
    "    # save model, optimizer and test_predictions if val_acc is improved\n",
    "    if valid_acc >= max_dev_acc:\n",
    "        print(f\"validation accuracy improved from {max_dev_acc:.4f} to {valid_acc:.4f}\")\n",
    "        name = \"pytorch_model\" + str(epoch_id) + \".bin\"\n",
    "        torch.save(s_model.state_dict(), os.path.join(CHECKPOINT_PATH, name))\n",
    "        print(\"Model saved at {} in epoch {}\".format(os.path.join(CHECKPOINT_PATH, name), epoch_id))\n",
    "\n",
    "        # re-assign\n",
    "        max_dev_acc, argmax_dev_acc = valid_acc, epoch_id\n",
    "        \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
